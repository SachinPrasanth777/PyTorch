{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCmEn6h9bUl2sPoHx/i/8b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SachinPrasanth777/PyTorch/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "60Mc4SlyjeHd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('anna.txt','r') as f:\n",
        "  text = f.read()\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPfq00rVkhNW",
        "outputId": "ceb18b89-6320-4858-f124-646d49c84e61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter 1\n",
            "\n",
            "\n",
            "Happy families are all alike; every unhappy family is unhappy in its own\n",
            "way.\n",
            "\n",
            "Everythin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = tuple(set(text))\n",
        "int2char = dict(enumerate(chars))\n",
        "char2int = {ch: ii for ii,ch in int2char.items()}\n",
        "encoded = np.array([char2int[ch] for ch in text])\n",
        "print(encoded[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nISO7VnlH5r",
        "outputId": "241055be-b412-4781-a23d-4c42e05cc5a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46 31 62 64 67 77 38 30 65 75 75 75 39 62 64 64  1 30 19 62 26 48 10 48\n",
            " 77 70 30 62 38 77 30 62 10 10 30 62 10 48 28 77 79 30 77 33 77 38  1 30\n",
            " 82 57 31 62 64 64  1 30 19 62 26 48 10  1 30 48 70 30 82 57 31 62 64 64\n",
            "  1 30 48 57 30 48 67 70 30 17  5 57 75  5 62  1  2 75 75 81 33 77 38  1\n",
            " 67 31 48 57]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(arr,n_labels):\n",
        "  one_hot = np.zeros((arr.size,n_labels), dtype = np.float32)\n",
        "  one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "  one_hot = one_hot.reshape((*arr.shape,n_labels))\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "J3cgvrJZnRy-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq = np.array([[3, 5, 1]])\n",
        "one_hot = one_hot_encode(test_seq, 8)\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9sy0EKloYL3",
        "outputId": "b2101248-8e32-4aca-ca93-4d25a4a3a289"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(arr,batch_size,seq_length):\n",
        "  batch_size_total = batch_size * seq_length\n",
        "  n_batches = len(arr)//batch_size_total\n",
        "  arr = arr[:n_batches * batch_size_total]\n",
        "  arr = arr.reshape((batch_size, -1))\n",
        "  x = np.zeros((batch_size, seq_length), dtype=arr.dtype)\n",
        "  y = np.zeros_like(x)\n",
        "  for n in range(0, arr.shape[1], seq_length):\n",
        "    x = arr[:, n:n+seq_length]\n",
        "    y = np.zeros_like(x)\n",
        "    try:\n",
        "      y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "    except IndexError:\n",
        "      y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "    yield x,y"
      ],
      "metadata": {
        "id": "jaqFCz8rpyje"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches = get_batches(encoded,8,50)\n",
        "x, y = next(batches)"
      ],
      "metadata": {
        "id": "2_J9sqQir4e0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x\\n', x[:10, :10])\n",
        "print('\\ny\\n', y[:10, :10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OExYMjrseoR",
        "outputId": "5250a871-72c8-49ff-e1d7-f050c56e1982"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x\n",
            " [[46 31 62 64 67 77 38 30 65 75]\n",
            " [70 17 57 30 67 31 62 67 30 62]\n",
            " [77 57 13 30 17 38 30 62 30 19]\n",
            " [70 30 67 31 77 30 51 31 48 77]\n",
            " [30 70 62  5 30 31 77 38 30 67]\n",
            " [51 82 70 70 48 17 57 30 62 57]\n",
            " [30 45 57 57 62 30 31 62 13 30]\n",
            " [68 32 10 17 57 70 28  1  2 30]]\n",
            "\n",
            "y\n",
            " [[31 62 64 67 77 38 30 65 75 75]\n",
            " [17 57 30 67 31 62 67 30 62 67]\n",
            " [57 13 30 17 38 30 62 30 19 17]\n",
            " [30 67 31 77 30 51 31 48 77 19]\n",
            " [70 62  5 30 31 77 38 30 67 77]\n",
            " [82 70 70 48 17 57 30 62 57 13]\n",
            " [45 57 57 62 30 31 62 13 30 70]\n",
            " [32 10 17 57 70 28  1  2 30  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU!')\n",
        "else:\n",
        "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5IBVez6taHw",
        "outputId": "15a5e446-fb32-4b1f-e35e-31d4764a9124"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, training on CPU; consider making n_epochs very small.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def init(self,tokens,n_hidden=256,n_layers=2,drop_prob=0.5,lr=0.001):\n",
        "    super().__init__()\n",
        "    self.drop_prob = drop_prob\n",
        "    self.n_layers = n_layers\n",
        "    self.n_hidden = n_hidden\n",
        "    self.lr = lr\n",
        "    self.chars = tokens\n",
        "    self.int2chars = dict(enumerate(self.chars))\n",
        "    self.lstm = nn.lstm(len(self.chars), n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    self.fc = nn.Linear(n_hidden, len(self.chars))\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        out = self.dropout(r_output)\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "  def init_hidden(self,batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    if(train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                weight.new(self.n_layers,batch_size, self.n_hidden).zero_())\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "HBDLLl4MuY_w"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}